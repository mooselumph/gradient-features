{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf372653",
   "metadata": {},
   "source": [
    "Jax Resources:\n",
    "https://jax.readthedocs.io/en/latest/faq.html#controlling-data-and-computation-placement-on-devices\n",
    "https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9954a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be35695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2,3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a922fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-4s8uqza1 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from typing import Generator, Mapping, Tuple\n",
    "\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from jax.tree_util import tree_flatten, tree_unflatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b843d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, task=0), GpuDevice(id=1, task=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54966f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7ff48",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6898a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = Mapping[str, np.ndarray]\n",
    "\n",
    "\n",
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(300), jax.nn.relu,\n",
    "      hk.Linear(100), jax.nn.relu,\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return mlp(x)\n",
    "\n",
    "\n",
    "def net_fn_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  cnn = hk.Sequential([\n",
    "      hk.Conv2D(24,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Conv2D(48,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return cnn(x)\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    is_training: bool,\n",
    "    batch_size: int,\n",
    ") -> Generator[Batch, None, None]:\n",
    "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
    "  ds = tfds.load(\"fashion_mnist:3.*.*\", split=split).cache().repeat()\n",
    "  if is_training:\n",
    "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
    "  ds = ds.batch(batch_size)\n",
    "  return iter(tfds.as_numpy(ds))\n",
    "\n",
    "# Make the network and optimiser.\n",
    "net = hk.without_apply_rng(hk.transform(net_fn_cnn))\n",
    "opt = optax.adam(1e-3)\n",
    "\n",
    "# Training loss (cross-entropy).\n",
    "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "    logits = net.apply(params, batch)\n",
    "    labels = jax.nn.one_hot(batch[\"label\"], 10)\n",
    "\n",
    "    l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "    softmax_xent /= labels.shape[0]\n",
    "\n",
    "    return softmax_xent + 1e-4 * l2_loss\n",
    "\n",
    "# Evaluation metric (classification accuracy).\n",
    "@jax.jit\n",
    "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    predictions = net.apply(params, batch)\n",
    "    return jnp.mean(jnp.argmax(predictions, axis=-1) == batch[\"label\"])\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    batch: Batch,\n",
    ") -> Tuple[hk.Params, optax.OptState]:\n",
    "    \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "    grads = jax.grad(loss)(params, batch)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "# We maintain avg_params, the exponential moving average of the \"live\" params.\n",
    "# avg_params is used only for evaluation (cf. https://doi.org/10.1137/0330046)\n",
    "@jax.jit\n",
    "def ema_update(params, avg_params):\n",
    "    return optax.incremental_update(params, avg_params, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cd188",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab1c27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train[0:10000]\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9add71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Train / Test accuracy: 0.076 / 0.079.\n",
      "[Step 1000] Train / Test accuracy: 0.878 / 0.869.\n",
      "[Step 2000] Train / Test accuracy: 0.888 / 0.881.\n",
      "[Step 3000] Train / Test accuracy: 0.886 / 0.879.\n",
      "[Step 4000] Train / Test accuracy: 0.886 / 0.877.\n",
      "[Step 5000] Train / Test accuracy: 0.888 / 0.877.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-87eae1b2f53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Do SGD on a batch of training examples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mavg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/api.py\u001b[0m in \u001b[0;36mf_jitted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0mf_jitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpp_jitted_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_jitted_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/haiku/_src/data_structures.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(treedef, leaves)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mFlatMapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_leaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     lambda treedef, leaves: FlatMapping(FlatComponents(leaves, treedef)))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;31m#      _                               _           _\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize network and optimiser; note we draw an input to get shapes.\n",
    "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "# Train/eval loop.\n",
    "for step in range(10001):\n",
    "    if step % 1000 == 0:\n",
    "        # Periodically evaluate classification accuracy on train & test sets.\n",
    "        train_accuracy = accuracy(avg_params, next(train_eval))\n",
    "        test_accuracy = accuracy(avg_params, next(test_eval))\n",
    "        train_accuracy, test_accuracy = jax.device_get(\n",
    "          (train_accuracy, test_accuracy))\n",
    "        print(f\"[Step {step}] Train / Test accuracy: \"\n",
    "            f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
    "\n",
    "    # Do SGD on a batch of training examples.\n",
    "    params, opt_state = update(params, opt_state, next(train))\n",
    "    avg_params = ema_update(params, avg_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaea115",
   "metadata": {},
   "source": [
    "## NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc04ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "567c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptwise_loss(params, batch):\n",
    "    batch['image'] = jnp.expand_dims(batch['image'],0)\n",
    "    batch['label'] = jnp.expand_dims(batch['label'],0)\n",
    "    return loss(params,batch)\n",
    "\n",
    "ptwise_grad = jax.vmap(jax.grad(ptwise_loss),in_axes=(None,{\"image\":0,\"label\":0}),out_axes=0)\n",
    "\n",
    "def ravel_pytree(pytree):\n",
    "    leaves, treedef = tree_flatten(pytree)\n",
    "    batch_size = leaves[0].shape[0]\n",
    "    return jnp.concatenate([jnp.reshape(elt,(batch_size,-1)) for elt in leaves],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9092fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=1000)\n",
    "batch = next(train_eval)\n",
    "\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "grads = ptwise_grad(params,batch)\n",
    "features = ravel_pytree(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5d56d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "item = {'image':jnp.expand_dims(batch['image'][0],0),'label':jnp.expand_dims(batch['label'][0],0)}\n",
    "normal_grads = jax.grad(loss)(params,item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c38139",
   "metadata": {},
   "source": [
    "## Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a51156ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "\n",
    "# Make datasets.\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=1)\n",
    "batch = next(train_eval)\n",
    "\n",
    "params = net.init(jax.random.PRNGKey(42), next(train_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30ecdc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.6 ms ± 925 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "f = lambda params: net.apply(params,batch)\n",
    "\n",
    "J = jacrev(f)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cbac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69e868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel_pytree(pytree):\n",
    "    leaves, treedef = tree_flatten(pytree)\n",
    "    batch_size = leaves[0].shape[0]\n",
    "    return jnp.concatenate([jnp.reshape(elt,(batch_size,-1)) for elt in leaves],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b339bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ravel_pytree(J)\n",
    "small_feat = features[:,:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8648542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 µs ± 3.43 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    t = np.asarray(small_feat)\n",
    "    j = jnp.asarray(t)\n",
    "    g = j @ j.T\n",
    "    \n",
    "    \n",
    "%timeit test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(\"train[0:10000]\", is_training=True, batch_size=10)\n",
    "\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "\n",
    "for batch in train:\n",
    "    \n",
    "    f = lambda params: net.apply(params,batch)\n",
    "    J = jacrev(f)(params)\n",
    "    features = ravel_pytree(J)\n",
    "    \n",
    "    # Dimensionality Reduce\n",
    "    \n",
    "    \n",
    "    # Send to CPU\n",
    "    \n",
    "    \n",
    "# pull all gradients back from cpu and construct matrix. \n",
    "# calculate gramm matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539f40c",
   "metadata": {},
   "source": [
    "## Estimate Expected Distance between Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "527cbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = hk.PRNGSequence(42)\n",
    "\n",
    "def avg_sim(features,labels,classes,rng_seq,num_iters=10000):\n",
    "    \n",
    "    n_classes = len(classes)\n",
    "    counts = np.zeros(shape=(n_classes,n_classes))\n",
    "    totals = np.zeros(shape=(n_classes,n_classes))\n",
    "    \n",
    "    batch_size = features.shape[0]\n",
    "    \n",
    "    # Randomly sample two points\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "    \n",
    "        [i,j]  = random.choice(next(rng_seq),np.arange(batch_size),shape=(2,),replace=False)\n",
    "        \n",
    "        prod = jnp.dot(features[i],features[j])\n",
    "        \n",
    "        indi = classes.index(labels[i])\n",
    "        indj = classes.index(labels[j])\n",
    "        \n",
    "        totals[indi,indj] += prod\n",
    "        counts[indi,indj] += 1\n",
    "    \n",
    "    totals = (totals + totals.T)/2\n",
    "    counts = (counts + counts.T)/2\n",
    "    \n",
    "\n",
    "    return totals/counts\n",
    "\n",
    "\n",
    "classes = list(range(10))\n",
    "labels = batch['label']\n",
    "\n",
    "sim = avg_sim(features,labels,classes,seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8f76445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f2df409a790>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sim)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
