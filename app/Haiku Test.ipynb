{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a922fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator, Mapping, Tuple\n",
    "\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from jax.tree_util import tree_flatten, tree_unflatten\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7ff48",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6898a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = Mapping[str, np.ndarray]\n",
    "\n",
    "\n",
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(300), jax.nn.relu,\n",
    "      hk.Linear(100), jax.nn.relu,\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return mlp(x)\n",
    "\n",
    "\n",
    "def net_fn_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  cnn = hk.Sequential([\n",
    "      hk.Conv2D(24,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Conv2D(48,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return cnn(x)\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    is_training: bool,\n",
    "    batch_size: int,\n",
    ") -> Generator[Batch, None, None]:\n",
    "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
    "  ds = tfds.load(\"mnist:3.*.*\", split=split).cache().repeat()\n",
    "  if is_training:\n",
    "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
    "  ds = ds.batch(batch_size)\n",
    "  return iter(tfds.as_numpy(ds))\n",
    "\n",
    "# Make the network and optimiser.\n",
    "net = hk.without_apply_rng(hk.transform(net_fn_cnn))\n",
    "opt = optax.adam(1e-3)\n",
    "\n",
    "# Training loss (cross-entropy).\n",
    "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "    logits = net.apply(params, batch)\n",
    "    labels = jax.nn.one_hot(batch[\"label\"], 10)\n",
    "\n",
    "    l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "    softmax_xent /= labels.shape[0]\n",
    "\n",
    "    return softmax_xent + 1e-4 * l2_loss\n",
    "\n",
    "# Evaluation metric (classification accuracy).\n",
    "@jax.jit\n",
    "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    predictions = net.apply(params, batch)\n",
    "    return jnp.mean(jnp.argmax(predictions, axis=-1) == batch[\"label\"])\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    batch: Batch,\n",
    ") -> Tuple[hk.Params, optax.OptState]:\n",
    "    \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "    grads = jax.grad(loss)(params, batch)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "# We maintain avg_params, the exponential moving average of the \"live\" params.\n",
    "# avg_params is used only for evaluation (cf. https://doi.org/10.1137/0330046)\n",
    "@jax.jit\n",
    "def ema_update(params, avg_params):\n",
    "    return optax.incremental_update(params, avg_params, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cd188",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9add71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Train / Test accuracy: 0.094 / 0.095.\n",
      "[Step 1000] Train / Test accuracy: 0.985 / 0.982.\n",
      "[Step 2000] Train / Test accuracy: 0.996 / 0.989.\n",
      "[Step 3000] Train / Test accuracy: 0.999 / 0.990.\n",
      "[Step 4000] Train / Test accuracy: 1.000 / 0.990.\n",
      "[Step 5000] Train / Test accuracy: 1.000 / 0.990.\n",
      "[Step 6000] Train / Test accuracy: 1.000 / 0.990.\n",
      "[Step 7000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 8000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 9000] Train / Test accuracy: 1.000 / 0.990.\n",
      "[Step 10000] Train / Test accuracy: 1.000 / 0.989.\n"
     ]
    }
   ],
   "source": [
    "# Initialize network and optimiser; note we draw an input to get shapes.\n",
    "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "# Train/eval loop.\n",
    "for step in range(10001):\n",
    "    if step % 1000 == 0:\n",
    "        # Periodically evaluate classification accuracy on train & test sets.\n",
    "        train_accuracy = accuracy(avg_params, next(train_eval))\n",
    "        test_accuracy = accuracy(avg_params, next(test_eval))\n",
    "        train_accuracy, test_accuracy = jax.device_get(\n",
    "          (train_accuracy, test_accuracy))\n",
    "        print(f\"[Step {step}] Train / Test accuracy: \"\n",
    "            f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
    "\n",
    "    # Do SGD on a batch of training examples.\n",
    "    params, opt_state = update(params, opt_state, next(train))\n",
    "    avg_params = ema_update(params, avg_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaea115",
   "metadata": {},
   "source": [
    "## NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc04ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptwise_loss(params, batch):\n",
    "    batch['image'] = jnp.expand_dims(batch['image'],0)\n",
    "    #batch['label'] = jnp.expand_dims(batch['label'],0)\n",
    "    return loss(params,batch)\n",
    "\n",
    "ptwise_grad = jax.vmap(jax.grad(ptwise_loss),in_axes=(None,{\"image\":0,\"label\":0}),out_axes=0)\n",
    "\n",
    "def ravel_pytree(pytree):\n",
    "    leaves, treedef = tree_flatten(grads)\n",
    "    batch_size = leaves[0].shape[0]\n",
    "    return jnp.concatenate([jnp.reshape(elt,(batch_size,-1)) for elt in leaves],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9092fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=1000)\n",
    "batch = next(train_eval)\n",
    "\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "grads = ptwise_grad(params,batch)\n",
    "features = ravel_pytree(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539f40c",
   "metadata": {},
   "source": [
    "## Estimate Expected Distance between Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527cbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = hk.PRNGSequence(42)\n",
    "\n",
    "def avg_sim(features,labels,classes,rng_seq,num_iters=1000):\n",
    "    \n",
    "    n_classes = len(classes)\n",
    "    counts = np.zeros(shape=(n_classes,n_classes))\n",
    "    totals = np.zeros(shape=(n_classes,n_classes))\n",
    "    \n",
    "    batch_size = features.shape[0]\n",
    "    \n",
    "    # Randomly sample two points\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "    \n",
    "        [i,j]  = random.choice(next(rng_seq),np.arange(batch_size),shape=(2,),replace=False)\n",
    "        \n",
    "        prod = jnp.dot(features[i],features[j])\n",
    "        \n",
    "        indi = classes.index(labels[i])\n",
    "        indj = classes.index(labels[j])\n",
    "        \n",
    "        totals[indi,indj] += prod\n",
    "        counts[indi,indj] += 1\n",
    "    \n",
    "    totals = (totals + totals.T)/2\n",
    "    counts = (counts + counts.T)/2\n",
    "    \n",
    "\n",
    "    return totals/counts\n",
    "\n",
    "\n",
    "classes = list(range(10))\n",
    "labels = batch['label']\n",
    "\n",
    "sim = avg_sim(features,labels,classes,seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8f76445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f45f00b5f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sim)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
