{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf372653",
   "metadata": {},
   "source": [
    "Jax Resources:\n",
    "https://jax.readthedocs.io/en/latest/faq.html#controlling-data-and-computation-placement-on-devices\n",
    "https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a9954a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 28.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.23\n",
      "  Downloading pandas-1.2.4-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 61.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.5)\n",
      "Collecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.4.1-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 64.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 114.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 106.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, pandas, matplotlib, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.1 pandas-1.2.4 pillow-8.2.0 seaborn-0.11.1\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/jovyan/.local/lib/python3.8/site-packages (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jovyan/.local/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jovyan/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jovyan/.local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be35695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2,3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a922fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-zzx43cmg because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from typing import Generator, Mapping, Tuple\n",
    "\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from jax.tree_util import tree_flatten, tree_unflatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b843d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, task=0), GpuDevice(id=1, task=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54966f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7ff48",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6898a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = Mapping[str, np.ndarray]\n",
    "\n",
    "\n",
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(300), jax.nn.relu,\n",
    "      hk.Linear(100), jax.nn.relu,\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return mlp(x)\n",
    "\n",
    "\n",
    "def net_fn_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "  x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "  cnn = hk.Sequential([\n",
    "      hk.Conv2D(24,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Conv2D(48,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(10),\n",
    "  ])\n",
    "  return cnn(x)\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    is_training: bool,\n",
    "    batch_size: int,\n",
    ") -> Generator[Batch, None, None]:\n",
    "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
    "  ds = tfds.load(\"mnist:3.*.*\", split=split).cache().repeat()\n",
    "  if is_training:\n",
    "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
    "  ds = ds.batch(batch_size)\n",
    "  return iter(tfds.as_numpy(ds))\n",
    "\n",
    "# Make the network and optimiser.\n",
    "net = hk.without_apply_rng(hk.transform(net_fn_cnn))\n",
    "opt = optax.adam(1e-3)\n",
    "\n",
    "# Training loss (cross-entropy).\n",
    "def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    \"\"\"Compute the loss of the network, including L2.\"\"\"\n",
    "    logits = net.apply(params, batch)\n",
    "    labels = jax.nn.one_hot(batch[\"label\"], 10)\n",
    "\n",
    "    l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "    softmax_xent /= labels.shape[0]\n",
    "\n",
    "    return softmax_xent + 1e-4 * l2_loss\n",
    "\n",
    "# Evaluation metric (classification accuracy).\n",
    "@jax.jit\n",
    "def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "    predictions = net.apply(params, batch)\n",
    "    return jnp.mean(jnp.argmax(predictions, axis=-1) == batch[\"label\"])\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    batch: Batch,\n",
    ") -> Tuple[hk.Params, optax.OptState]:\n",
    "    \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "    grads = jax.grad(loss)(params, batch)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "# We maintain avg_params, the exponential moving average of the \"live\" params.\n",
    "# avg_params is used only for evaluation (cf. https://doi.org/10.1137/0330046)\n",
    "@jax.jit\n",
    "def ema_update(params, avg_params):\n",
    "    return optax.incremental_update(params, avg_params, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cd188",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1c27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9add71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Train / Test accuracy: 0.094 / 0.095.\n",
      "[Step 1000] Train / Test accuracy: 0.985 / 0.982.\n",
      "[Step 2000] Train / Test accuracy: 0.996 / 0.990.\n",
      "[Step 3000] Train / Test accuracy: 0.999 / 0.990.\n",
      "[Step 4000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 5000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 6000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 7000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 8000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 9000] Train / Test accuracy: 1.000 / 0.989.\n",
      "[Step 10000] Train / Test accuracy: 1.000 / 0.990.\n"
     ]
    }
   ],
   "source": [
    "# Initialize network and optimiser; note we draw an input to get shapes.\n",
    "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "# Train/eval loop.\n",
    "for step in range(10001):\n",
    "    if step % 1000 == 0:\n",
    "        # Periodically evaluate classification accuracy on train & test sets.\n",
    "        train_accuracy = accuracy(avg_params, next(train_eval))\n",
    "        test_accuracy = accuracy(avg_params, next(test_eval))\n",
    "        train_accuracy, test_accuracy = jax.device_get(\n",
    "          (train_accuracy, test_accuracy))\n",
    "        print(f\"[Step {step}] Train / Test accuracy: \"\n",
    "            f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
    "\n",
    "    # Do SGD on a batch of training examples.\n",
    "    params, opt_state = update(params, opt_state, next(train))\n",
    "    avg_params = ema_update(params, avg_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaea115",
   "metadata": {},
   "source": [
    "## NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc04ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets.\n",
    "train = load_dataset(\"train\", is_training=True, batch_size=1000)\n",
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=10000)\n",
    "test_eval = load_dataset(\"test\", is_training=False, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptwise_loss(params, batch):\n",
    "    batch['image'] = jnp.expand_dims(batch['image'],0)\n",
    "    batch['label'] = jnp.expand_dims(batch['label'],0)\n",
    "    return loss(params,batch)\n",
    "\n",
    "ptwise_grad = jax.vmap(jax.grad(ptwise_loss),in_axes=(None,{\"image\":0,\"label\":0}),out_axes=0)\n",
    "\n",
    "def ravel_pytree(pytree):\n",
    "    leaves, treedef = tree_flatten(grads)\n",
    "    batch_size = leaves[0].shape[0]\n",
    "    return jnp.concatenate([jnp.reshape(elt,(batch_size,-1)) for elt in leaves],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9092fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = load_dataset(\"train\", is_training=False, batch_size=1000)\n",
    "batch = next(train_eval)\n",
    "\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "grads = ptwise_grad(params,batch)\n",
    "features = ravel_pytree(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5d56d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "item = {'image':jnp.expand_dims(batch['image'][0],0),'label':jnp.expand_dims(batch['label'][0],0)}\n",
    "normal_grads = jax.grad(loss)(params,item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539f40c",
   "metadata": {},
   "source": [
    "## Estimate Expected Distance between Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527cbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = hk.PRNGSequence(42)\n",
    "\n",
    "def avg_sim(features,labels,classes,rng_seq,num_iters=10000):\n",
    "    \n",
    "    n_classes = len(classes)\n",
    "    counts = np.zeros(shape=(n_classes,n_classes))\n",
    "    totals = np.zeros(shape=(n_classes,n_classes))\n",
    "    \n",
    "    batch_size = features.shape[0]\n",
    "    \n",
    "    # Randomly sample two points\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "    \n",
    "        [i,j]  = random.choice(next(rng_seq),np.arange(batch_size),shape=(2,),replace=False)\n",
    "        \n",
    "        prod = jnp.dot(features[i],features[j])\n",
    "        \n",
    "        indi = classes.index(labels[i])\n",
    "        indj = classes.index(labels[j])\n",
    "        \n",
    "        totals[indi,indj] += prod\n",
    "        counts[indi,indj] += 1\n",
    "    \n",
    "    totals = (totals + totals.T)/2\n",
    "    counts = (counts + counts.T)/2\n",
    "    \n",
    "\n",
    "    return totals/counts\n",
    "\n",
    "\n",
    "classes = list(range(10))\n",
    "labels = batch['label']\n",
    "\n",
    "sim = avg_sim(features,labels,classes,seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f76445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f8e145c2f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD4CAYAAABbu6u/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUjklEQVR4nO3dfYxddZ3H8fenU1r6IFC2LAtt2Tak6qKJQCaIsnFVXAV0rSYbAhuVdcnW3YCiS2KAf/AfNv6Bj1lDUgGFyMISxMAaAiJqjIki5SFAWwiVp7YWSmUpBS1t73z2j3tmvVs7c8/MnDP33J7PKznpvWfOfO+3MPPt7+Gc30+2iYhosjmDTiAiop8UqohovBSqiGi8FKqIaLwUqohovLl1BF169IhXrjis8rhPPXFk5TEBqGPmUzX9G9Dp1BLWY2O1xNW86n8OAOjUkO/ckepjAuzbX3nIP4ztZu/YHs0kxofet8i/e7ncz9ODj75xj+2zZvJ5M1FLoVq54jB+fc+KyuN++F1/V3lMAN7YW33MBYdXHxPwK6/WEnfstddriTvnhGW1xGV3DfkeXdM/hNt3VB7yl6/eMeMYO1/ucP89y0tde9hxv1k64w+cgVoKVUQMA9NxPS3pqqVQRbSUgTGG44bvFKqIFhsjLaqIaDBj9qXrFxFNZqCTrl9ENN2wjFGVutlH0lmSnpS0WdJldScVEfUz0LFLHYPWt1BJGgG+BZwNnAScL+mkuhOLiPqNlTwGrUyL6jRgs+2nbe8FbgHW1JtWRNTNmE7JY9DKjFEtA7b0vN8KvPPAiyStBdYCnLAsQ18RTWfDvsHXoFIqeyDN9jrbo7ZHj/mzmp6ZiogKiU7JY9DKNH22Ab0P7i0vzkXEEDMwNiQtqjKF6gFgtaRVdAvUecA/1JpVRMyKJrSWyuhbqGzvl3QxcA8wAlxve0PtmUVErbo3fB4ihQrA9l3AXTXnEhGzyMA+D8famZmei2gpIzpDsshvClVEi435EOr6RcSh55Abo4qIQ5HoZIwqIpqsu8JniwvVU08cWctGDL/5p+o3jAA48drnK4/pmnY00RGLa4k7snhRLXFr2S0GYN686mPuqWGTD4AFC6qP+drMu2y22OuZ/5xKWgHcCBxLt/6ts/0NSV8C/hl4qbj0iuIOAiRdDlwIdIDP2b5nss9IiyqixcaqGaPaD1xq+yFJbwIelHRv8bWv2b669+Ji9ZXzgLcBxwM/lvRm2xPu3ZVCFdFS3cH0mXf9bG8Hthevd0vaRHcxg4msAW6x/QbwjKTNdFdp+eVE3zAcHdSIqEF3ML3MUTqitBI4Bbi/OHWxpEclXS9pSXHuYCuyTLoBZApVREuND6aXOYClktb3HGsPjCdpMfB94PO2XwWuAU4ETqbb4vrKdHNN1y+ixTrlb/jcaXt0oi9KOoxukbrJ9u0Atl/s+fq3gR8Wb6e8IktaVBEtZcQ+zy11TEaSgOuATba/2nP+uJ7LPg48Xry+EzhP0vxiVZbVwK8n+4y0qCJaqqrBdOAM4JPAY5IeKc5dQXd/hZOLj3oW+AyA7Q2SbgU20p0xvGiyGT9IoYpoLaOpdP0mjmP/Ag56n8OEK67Yvgq4quxnpFBFtFir70yPiOazybN+EdFs3cH04diIJYUqosWycF5ENJpRFs6LiOZLiyoiGq27r18KVUQ0WjN2QS4jhSqipbrbZWXWLyIazFa6fhHRfLnhMyIarbseVcaoIqLR2r5dlg1vVL+jRx27xQCc8t/PVR7zoQ8d1/+iaRh77fVa4mqkpl1zFtawAwvgGn6+mFvPr8PYK7sqj+n9k66KUi4G2Sk5Ihouz/pFxFDIMi8R0WjdZV7S9YuIhssYVUQ0Wnf1hHT9IqLBuo/QpFBFRKMNT4uqb5aSVkj6qaSNkjZIumQ2EouI+o2hUseglWlR7Qcutf2QpDcBD0q61/bGmnOLiBodUrN+trfT3Tce27slbQKW0d08MCKG2LB0/aY0RiVpJXAKcP9BvrYWWAtw+MjiKnKLiBoN05rppcuppMXA94HP2371wK/bXmd71PbovDn1PN8VEdUxsN9zSh2TmWgcW9LRku6V9FTx55LivCR9U9JmSY9KOrVfrqUKlaTD6Bapm2zfXuZ7IqL5xjyn1NHH+Dj2ScDpwEWSTgIuA+6zvRq4r3gPcDawujjWAtf0+4Ays34CrgM22f5qv+sjYki42/Urc0waxt5u+6Hi9W5gfBx7DXBDcdkNwMeK12uAG931K+AoSZMuN1KmRXUG8Eng/ZIeKY5zSnxfRDTY+MJ5JW9PWCppfc+x9mAxDxjHPraYjAN4ATi2eL0M2NLzbVuLcxMqM+v3C2jAjRQRUbkpDKbvtD062QUHjmN3O2Ndti3J080zd6ZHtFSVC+dNMI79oqTjbG8vunY7ivPbgBU93768ODeh4biJIiIqZ8T+sTmljslMMo59J3BB8foC4I6e858qZv9OB3b1dBEPKi2qiBar6PGY8XHsxyQ9Upy7AvgycKukC4HngHOLr90FnANsBn4PfLrfB6RQRbSVq+n69RnHPvMg1xu4aCqfUU+h0hxYcHjlYT23nvWd69iI4W9+/EzlMQF+/pG31hLXNW0aUdeGCb0DtVXxkiMqjwmgPXuqj7m/ggJDFs6LiCGQQhURjWZEp89AeVOkUEW0WBPWmiojhSqipVzRYPpsSKGKaDGnUEVEsw3PelQpVBEtlhZVRDSaDZ2xFKqIaLjM+kVEo5l0/SKi8TKYHhFDwNNeym52pVBFtFi6fhHRaN1ZvzzrFxENl65fRDReun4R0WhGKVQR0XxD0vNLoYpoLYPzCE1ENF26fhHReO2e9et08CuvVh5WRyyuPCbAWA07sNS1W8ye6+r5F3D++fXs8OMadmAB0Pz51cd8eVflMQE6u3dXHtMem3kM0qKKiKYzMCSFajhuS42IWtjljn4kXS9ph6THe859SdI2SY8Uxzk9X7tc0mZJT0r6UL/4aVFFtJaqnPX7LvAfwI0HnP+a7av/36dKJwHnAW8Djgd+LOnNtjsTBU+LKqLNXPLoF8b+OfByyU9dA9xi+w3bzwCbgdMm+4YUqoi2cncwvcwBLJW0vudYW/JTLpb0aNE1XFKcWwZs6blma3FuQilUEW1WvkW10/Zoz7GuRPRrgBOBk4HtwFemm2YKVUSrqeQxdbZftN1x916Kb/PH7t02YEXPpcuLcxMqXagkjUh6WNIPp5pwRDTUWMljGiQd1/P248D4jOCdwHmS5ktaBawGfj1ZrKnM+l0CbAKOmML3RERTVXgflaSbgffSHcvaClwJvFfSycUnPQt8BsD2Bkm3AhuB/cBFk834QclCJWk58GHgKuDfpvMXiYjmqeoRGtvnH+T0dZNcfxXdelJK2a7f14EvMkkjUNLa8RmBva7nsYmIqFhFtyfUrW+hkvQRYIftBye7zva68RmBeTq8sgQjokZWuWPAynT9zgA+Wtz+fjhwhKTv2f5EvalFRN3UgNZSGX1bVLYvt73c9kq6t73/JEUq4hBgwVjJY8DyrF9Emw1Ji2pKhcr2z4Cf1ZJJRMy+Q7FQRcQhJoUqIhptiBbOS6GKaLFhmfVLoYposxSqiGi6VreoPDZWy84uI4sXVR4TQCPV78DiGv7+UN9uMS9ev6T/RdPwF//yWi1xa9ndpjPpc7HTprk1/JrtryhOxqgiotEa8hxfGSlUEW2WQhURTaeZ72M6K1KoItosLaqIaDK55bN+ETEkMusXEY2XFlVENF26fhHRbM6sX0QMg7SoIqLxUqgioumGZYyq9JbuERETkXS9pB2SHu85d7SkeyU9Vfy5pDgvSd+UtFnSo5JO7Rc/hSqizarbgPS7wFkHnLsMuM/2auC+4j3A2cDq4lgLXNMveApVRFsVs35ljr6h7J8DLx9weg1wQ/H6BuBjPedvdNevgKMkHTdZ/BSqiDYr36JaKml9z7G2RPRjbW8vXr8AHFu8XgZs6blua3FuQhlMj2gpMaXB9J22R6f7WbYtTX/oPi2qiDarbozqYF4c79IVf+4ozm8DVvRct7w4N6EUqoi28h9XUOh3TNOdwAXF6wuAO3rOf6qY/Tsd2NXTRTyodP0i2qyiR2gk3Qy8l+5Y1lbgSuDLwK2SLgSeA84tLr8LOAfYDPwe+HS/+ClUES1W1Q2fts+f4EtnHuRaAxdNJX4thUrzDmPOCZMO4k9Pp54nKLVwQfVB69h5hJp2X6G+3WJG73qulrgPfLD6ny/VtMuRX9lVQ9CGxalZWlQRbZVdaCJiGAzLs34pVBFtlkIVEU2XhfMiotkyRhURTafiGAYpVBFtNiQtqlKP0Eg6StJtkp6QtEnSu+pOLCLqV/MjNJUp26L6BnC37b+XNA9YWGNOETFbGlCEyuhbqCQdCbwH+EcA23uBvfWmFRG1G6Ltssp0/VYBLwHfkfSwpGsl/cmzBpLWji+qtbfzh8oTjYga1LvMS2XKFKq5wKnANbZPAV7nj2sf/x/b62yP2h6dN1LDs3MRUblhGaMqU6i2Altt31+8v41u4YqIYXeotKhsvwBskfSW4tSZwMZas4qIWTEsLaqys36fBW4qZvyepsRCVxHRcKayhfPqVqpQ2X4EmPbC7hHRPFPc3GGgcmd6RJulUEVE08nDUalSqCLaqiEzemWkUEW0WMaoIqLxhuURmnoKVWcMdr9efdx586qPCfiN6h9dlOpZ6Ufz59cSt67dberYLQbg+WuOqTzmCf/6UuUxAUaOqT5XvVzRr25aVBHRaA25mbOMFKqINquoUEl6FtgNdID9tkclHQ38F7ASeBY41/b/TCd+qYXzIuLQM37DZ4WP0LzP9sm2x28Ovwy4z/Zq4D4OsphBWSlUES2mMZc6pmkNcEPx+gbgY9MNlEIV0VZlV04oV6cM/EjSg5LWFueOtb29eP0CcOx0U80YVUSLTeH2hKWS1ve8X2d7Xc/7v7a9TdKfA/dKeqL3m21bmv7QfQpVRJuVLx07e8ae/jSMva34c4ekHwCnAS9KOs72dknHATumm2a6fhEtVsVguqRFkt40/hr4IPA4cCdwQXHZBcAd080zLaqItjJQzUPJxwI/KG5yngv8p+27JT0A3CrpQuA54NzpfkAKVUSLVfEIje2ngXcc5Pzv6K4IPGMpVBEtlYXzIqL57Kq6frVLoYposbSoIqL5UqgiounSooqIZjPQGY5KlUIV0WJpUUVE82XWLyKaLi2qiGi21m+XNXcEjj6y+rh7qt+EAYC51f9n8JIjKo8JoJd31RKXTqeWsFq8qJa4dWzEcNkvf1R5TIB//6t3Vh7TFfz/EqAMpkdE02Wn5IhottZ3/SJiCORZv4gYApn1i4jmS4sqIhrNmfWLiGEwHHWq3OYOkr4gaYOkxyXdLOnwuhOLiPrJLnUMWt9CJWkZ8Dlg1PbbgRHgvLoTi4hZML7KZ79jwMp2/eYCCyTtAxYCv60vpYiYFQYq2NxhNvRtURUbC14NPA9sB3bZ/pNnDSStlbRe0vq9nd9Xn2lEVEqU6/YNS9dvCbAGWAUcDyyS9IkDr7O9zvao7dF5IwurzzQiqjc2Vu4YsDKD6R8AnrH9ku19wO3Au+tNKyJqN971K3MMWJkxqueB0yUtBP5Ad0PB9bVmFRGzogndujLKjFHdD9wGPAQ8VnzPuprziojZUNGsn6SzJD0pabOky6pOs9Ssn+0rgSur/vCIGKRqbj2QNAJ8C/hbYCvwgKQ7bW+ccfBCqRs+I+IQNL4LTZljcqcBm20/bXsvcAvdCbjK5BGaiBabwhjVUkm9Y9PrbI8PAS0DtvR8bStQ6bKmKVQRbVa+UO20PVpnKpNJoYpoKwNjlcz6bQNW9LxfXpyrTMaoIlqr5Ixf/1bXA8BqSaskzaP7LPCdVWZaT4tq337YvqP6uAsWVB8TGHul+p1dtGdP5TEBOrt31xJXNezEA+Aa/tsCjBxzTOUx69gtBmDbLSdWHnPfpfOrCVTBrJ/t/ZIuBu6hu2jB9bY3zDhwj3T9ItrKQKea285t3wXcVUmwg0ihimgtgxvwfEwJKVQRbTYkj9CkUEW0VXWzfrVLoYpos7SoIqLxUqgiotFs6HQGnUUpKVQRbZYWVUQ0XgpVRDSbM+sXEQ1ncG74jIjGq+gRmrqlUEW0ld2IrbDKSKGKaLMMpkdE0zktqohotmp2oZkNKVQRbZWHkiOi6Qw4j9BERKM5C+dFxBBwun4R0XhD0qKSaxj1l/QS8FyJS5cCOytPoD7DlO8w5QrDlW8Tcv1L2zPaikfS3XT/LmXstH3WTD5vJmopVKU/XFo/yN1Xp2qY8h2mXGG48h2mXA8V2YA0IhovhSoiGm/QhWrdgD9/qoYp32HKFYYr32HK9ZAw0DGqiIgyBt2iiojoK4UqIhpvYIVK0lmSnpS0WdJlg8qjH0krJP1U0kZJGyRdMuicypA0IulhST8cdC6TkXSUpNskPSFpk6R3DTqnyUj6QvFz8LikmyUdPuic2mAghUrSCPAt4GzgJOB8SScNIpcS9gOX2j4JOB24qMG59roE2DToJEr4BnC37bcC76DBOUtaBnwOGLX9dmAEOG+wWbXDoFpUpwGbbT9tey9wC7BmQLlMyvZ22w8Vr3fT/UVaNtisJidpOfBh4NpB5zIZSUcC7wGuA7C91/YrA02qv7nAAklzgYXAbwecTysMqlAtA7b0vN9Kw3/5ASStBE4B7h9wKv18Hfgi0PQHuVYBLwHfKbqp10paNOikJmJ7G3A18DywHdhl+0eDzaodMphekqTFwPeBz9t+ddD5TETSR4Adth8cdC4lzAVOBa6xfQrwOtDk8coldFv+q4DjgUWSPjHYrNphUIVqG7Ci5/3y4lwjSTqMbpG6yfbtg86njzOAj0p6lm6X+v2SvjfYlCa0Fdhqe7yFehvdwtVUHwCesf2S7X3A7cC7B5xTKwyqUD0ArJa0StI8ugOSdw4ol0lJEt0xlE22vzrofPqxfbnt5bZX0v3v+hPbjfxX3/YLwBZJbylOnQlsHGBK/TwPnC5pYfFzcSYNHvw/lAxkPSrb+yVdDNxDd+bketsbBpFLCWcAnwQek/RIce4K23cNLqVDymeBm4p/sJ4GPj3gfCZk+35JtwEP0Z0Nfpg8TjMr8ghNRDReBtMjovFSqCKi8VKoIqLxUqgiovFSqCKi8VKoIqLxUqgiovH+FxCaw/12XescAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sim)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
