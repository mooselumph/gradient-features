{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975ac9c0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01342bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-3ux8hihn because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "from typing import Generator, Mapping, Tuple\n",
    "\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "Batch = Mapping[str, np.ndarray]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fc776",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8e261",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd92f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset: str, split: str, *, is_training: bool, \n",
    "                 batch_size: int) -> Generator[Batch, None, None]:\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        ds = tfds.load(\"cifar10\", split=split).cache().repeat()\n",
    "    elif dataset == \"mnist\":\n",
    "        ds = tfds.load(\"mnist:3.*.*\", split=split).cache().repeat()\n",
    "    else:\n",
    "        raise Exception(\"Invalid Dataset\")\n",
    "    if is_training:\n",
    "        ds = ds.shuffle(10 * batch_size, seed=0)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return iter(tfds.as_numpy(ds))\n",
    "\n",
    "def get_mnist_data(batch_size=1000):\n",
    "    train = load_dataset(\"mnist\", \"train\", is_training=True, batch_size=batch_size)\n",
    "    train_eval = load_dataset(\"mnist\", \"train\", is_training=False, batch_size=batch_size)\n",
    "    test_eval = load_dataset(\"mnist\", \"test\", is_training=False, batch_size=batch_size)\n",
    "    return train, train_eval, test_eval\n",
    "\n",
    "    \n",
    "\n",
    "def softmax_xent_loss(net):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        net: network function (with apply and init funcs)\n",
    "    \n",
    "    Returns:\n",
    "        loss_fn: function(params, batch) --> loss\n",
    "        \n",
    "    Creates softmax cross entropy loss function for a given network\n",
    "    \"\"\"\n",
    "    @jax.jit\n",
    "    def loss(params, batch):\n",
    "        logits = net.apply(params, batch)\n",
    "        labels = jax.nn.one_hot(batch[\"label\"], 10)\n",
    "\n",
    "        l2_loss = 0.5 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
    "        softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "        softmax_xent /= labels.shape[0]\n",
    "\n",
    "        return softmax_xent + 1e-4 * l2_loss\n",
    "    \n",
    "    return loss \n",
    "\n",
    "\n",
    "def ptwise_grads(loss_fn):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        loss_fn: function(params, batch) --> loss \n",
    "    \n",
    "    Returns:\n",
    "        function(params, batch) --> pointwise gradients\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def helper(params, batch):\n",
    "        batch['image'] = jnp.expand_dims(batch['image'], axis=0)\n",
    "        batch['label'] = jnp.expand_dims(batch['label'], axis=0)\n",
    "        return jax.grad(loss_fn)(params, batch)\n",
    "    \n",
    "    return jax.jit(jax.vmap(helper, in_axes=(None, {'image': 0, 'label': 0}), out_axes=0))\n",
    "\n",
    "\n",
    "# Returns both network and loss given net function so as to not mistakenly use incompatible functions\n",
    "def network_and_loss(net_fn, rng=False):\n",
    "    if not rng:\n",
    "        net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "    else:\n",
    "        net = hk.transform(net_fn)\n",
    "        \n",
    "    loss_fn = softmax_xent_loss(net)\n",
    "    \n",
    "    return net, loss_fn\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef5c0c",
   "metadata": {},
   "source": [
    "## Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcaf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_fn(batch: Batch) -> jnp.ndarray:\n",
    "    \"\"\"Standard LeNet-300-100 MLP network.\"\"\"\n",
    "    x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "    mlp = hk.Sequential([\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(300), jax.nn.relu,\n",
    "      hk.Linear(100), jax.nn.relu,\n",
    "      hk.Linear(10),\n",
    "    ])\n",
    "    return mlp(x)\n",
    "\n",
    "\n",
    "def net_fn_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Vanilla CNN for MNIST\"\"\"\n",
    "    x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "    cnn = hk.Sequential([\n",
    "      hk.Conv2D(24,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Conv2D(48,5),\n",
    "      hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "      hk.Flatten(),\n",
    "      hk.Linear(10),\n",
    "    ])\n",
    "    return cnn(x)\n",
    "\n",
    "def deeper_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Slightly deeper CNN for MNIST\"\"\"\n",
    "    x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "    cnn = hk.Sequential([\n",
    "        hk.Conv2D(24,5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Conv2D(48,5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Conv2D(64, 5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(10),\n",
    "    ])\n",
    "    return cnn(x)\n",
    "\n",
    "def deepest_cnn(batch: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Slightly deeper CNN for MNIST\"\"\"\n",
    "    x = batch[\"image\"].astype(jnp.float32) / 255.\n",
    "    cnn = hk.Sequential([\n",
    "        hk.Conv2D(24,5), jax.nn.relu,\n",
    "        hk.Conv2D(24,5), jax.nn.relu,\n",
    "        hk.Conv2D(24,5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Conv2D(48,5), jax.nn.relu,\n",
    "        hk.Conv2D(48, 5), jax.nn.relu,\n",
    "        hk.Conv2D(48, 5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Conv2D(96, 5), jax.nn.relu,\n",
    "        hk.Conv2D(96, 5), jax.nn.relu,\n",
    "        hk.Conv2D(96, 5), jax.nn.relu,\n",
    "        hk.MaxPool(window_shape=2, strides=2, padding=\"VALID\", channel_axis=- 1, name=None),\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(10),\n",
    "    ])\n",
    "    return cnn(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02716b4d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c71e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_accuracy(net):  \n",
    "    @jax.jit\n",
    "    def accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "        predictions = net.apply(params, batch)\n",
    "        return jnp.mean(jnp.argmax(predictions, axis=-1) == batch[\"label\"])\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def update_params(loss_fn):   \n",
    "    @jax.jit\n",
    "    def update(\n",
    "      params: hk.Params,\n",
    "      opt_state: optax.OptState,\n",
    "      batch: Batch,\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        grads = jax.grad(loss_fn)(params, batch)\n",
    "        updates, opt_state = opt.update(grads, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, opt_state\n",
    "    return update\n",
    "\n",
    "# We maintain avg_params, the exponential moving average of the \"live\" params.\n",
    "# avg_params is used only for evaluation (cf. https://doi.org/10.1137/0330046)\n",
    "@jax.jit\n",
    "def ema_update(params, avg_params):\n",
    "    return optax.incremental_update(params, avg_params, step_size=0.001)\n",
    "\n",
    "def do_training(net, loss_fn, params, opt_state, train, train_eval, test_eval, epochs=10001, print_epoch=1000):\n",
    "\n",
    "    accuracy = net_accuracy(net)\n",
    "    update = update_params(loss_fn)\n",
    "    avg_params = params\n",
    "    \n",
    "    # Train/eval loop.\n",
    "    for step in range(epochs):\n",
    "        if step % print_epoch == 0:\n",
    "            # Periodically evaluate classification accuracy on train & test sets.\n",
    "            train_accuracy = accuracy(avg_params, next(train_eval))\n",
    "            test_accuracy = accuracy(avg_params, next(test_eval))\n",
    "            train_accuracy, test_accuracy = jax.device_get(\n",
    "              (train_accuracy, test_accuracy))\n",
    "            print(f\"[Step {step}] Train / Test accuracy: \"\n",
    "                f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
    "\n",
    "        # Do SGD on a batch of training examples.\n",
    "        params, opt_state = update(params, opt_state, next(train))\n",
    "        avg_params = ema_update(params, avg_params)\n",
    "    \n",
    "    return avg_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bb2e8",
   "metadata": {},
   "source": [
    "## Compute Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe218237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel_pytree(pytree):\n",
    "    leaves, treedef = jax.tree_flatten(pytree)\n",
    "    batch_size = leaves[0].shape[0]\n",
    "    return jnp.concatenate([jnp.reshape(elt,(batch_size,-1)) for elt in leaves],axis=1)\n",
    "\n",
    "def avg_sim(features,labels,classes,seq,num_iters=1000):\n",
    "    \n",
    "    n_classes = len(classes)\n",
    "    counts = np.zeros(shape=(n_classes,n_classes))\n",
    "    totals = np.zeros(shape=(n_classes,n_classes))\n",
    "    \n",
    "    batch_size = features.shape[0]\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "    \n",
    "        \n",
    "        # sample two points, dot them\n",
    "        [i,j]  = random.choice(next(seq),np.arange(batch_size),shape=(2,),replace=False)\n",
    "        prod = jnp.dot(features[i],features[j])\n",
    "        \n",
    "        indi = classes.index(labels[i])\n",
    "        indj = classes.index(labels[j])\n",
    "        \n",
    "        totals[indi,indj] += prod\n",
    "        counts[indi,indj] += 1\n",
    "    \n",
    "    totals = (totals + totals.T)/2\n",
    "    counts = (counts + counts.T)/2\n",
    "    print(counts)\n",
    "    \n",
    "\n",
    "    return totals/counts\n",
    "\n",
    "\n",
    "def new_avg_sim(loss, params, batch, seq, num_iters=100, minibatch_size=10):\n",
    "    \n",
    "    classes = list(range(10))\n",
    "    n_classes = len(classes)\n",
    "    counts = np.zeros(shape=(n_classes,n_classes))\n",
    "    totals = np.zeros(shape=(n_classes,n_classes))\n",
    "    batch_size = batch['image'].shape[0]\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        # 1) randomly select minibatch of size minibatch_size\n",
    "        # 2) compute pointwise gradients for each sample in minibatch\n",
    "        # 3) compute pairwise inner products between all pointwise gradients in minibatch\n",
    "        \n",
    "        # (1)\n",
    "        batch_selection = np.arange(batch_size)\n",
    "        minibatch_idx = random.choice(next(seq), batch_selection, shape=(minibatch_size,), replace=False)\n",
    "        minibatch = jnp.take(batch['image'], minibatch_idx, axis=0)\n",
    "        minibatch_labels = jnp.take(batch['label'], minibatch_idx, axis=0)\n",
    "        \n",
    "        # (2)\n",
    "        compute_pointwise_grads = ptwise_grads(loss)\n",
    "        pointwise_grads = compute_pointwise_grads(params, {'image': minibatch, 'label': minibatch_labels})\n",
    "        \n",
    "        # (3)\n",
    "        features = ravel_pytree(pointwise_grads)\n",
    "        for i in range(minibatch_size):\n",
    "            for j in range(minibatch_size):\n",
    "                if j >= i:\n",
    "                    continue\n",
    "                prod = jnp.dot(features[i], features[j])\n",
    "                \n",
    "                indi = classes.index(minibatch_labels[i])\n",
    "                indj = classes.index(minibatch_labels[j])\n",
    "                \n",
    "                totals[indi,indj] += prod\n",
    "                counts[indi,indj] += 1\n",
    "                \n",
    "    # (4)\n",
    "    totals = (totals + totals.T)/2\n",
    "    counts = (counts + counts.T)/2\n",
    "    print(counts)\n",
    "    \n",
    "\n",
    "    return totals/counts\n",
    "   \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "def compute_distances(loss, params, batch, iters=1000, prng_seq=None):\n",
    "    compute_pointwise_gradients = ptwise_grads(loss)\n",
    "    pointwise_gradients = compute_pointwise_gradients(params, batch)\n",
    "    return avg_sim(ravel_pytree(pointwise_gradients), batch['label'], \n",
    "                   list(range(10)), prng_seq if prng_seq else hk.PRNGSequence(42), num_iters=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef97793",
   "metadata": {},
   "source": [
    "# Do Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5c063",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4204a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data\n",
    "train, train_eval, test_eval = get_mnist_data()\n",
    "\n",
    "# cnn, loss, params\n",
    "cnn, xent_loss = network_and_loss(net_fn_cnn)\n",
    "params = cnn.init(jax.random.PRNGKey(42), next(train))\n",
    "\n",
    "# optimization of network\n",
    "opt = optax.adam(1e-3)\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "# train cnn\n",
    "final_params = do_training(cnn, xent_loss, params, opt_state, train, train_eval, test_eval, epochs=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18261d",
   "metadata": {},
   "source": [
    "## Gradient distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single, constant batch for replicable results\n",
    "train = load_dataset(\"mnist\", \"train\", is_training=True, batch_size=1000)\n",
    "batch = next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08acf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_initial_distances = compute_distances(xent_loss, params, batch)\n",
    "t_final_distances = compute_distances(xent_loss, final_params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e734ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial distances\n",
    "plt.imshow(t_initial_distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57875b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final distances\n",
    "plt.imshow(t_final_distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f51b75",
   "metadata": {},
   "source": [
    "## Deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc043a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_eval, test_eval = get_mnist_data()\n",
    "batch = next(train)\n",
    "batch = next(train)\n",
    "\n",
    "deep_cnn, loss = network_and_loss(deeper_cnn)\n",
    "params = deep_cnn.init(jax.random.PRNGKey(34), next(train))\n",
    "print(batch['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3421f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = compute_distances(loss, params, batch, 7000)\n",
    "plt.imshow(distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b335e5",
   "metadata": {},
   "source": [
    "## Even Deeper\n",
    "\n",
    "Note: For larger networks with more parameters, it will be infeasible to store all of the pointwise gradients at the same time. Instead we will have to perform the pointwise gradient computation on minibatches of a given batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38481e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even deeper\n",
    "train, train_eval, test_eval = get_mnist_data(1000)\n",
    "batch = next(train)\n",
    "\n",
    "\n",
    "cnn, loss = network_and_loss(deepest_cnn)\n",
    "params = cnn.init(jax.random.PRNGKey(2), next(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c36a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = new_avg_sim(loss, params, batch, hk.PRNGSequence(42), num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5339fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adam(1e-3)\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "final_params = do_training(cnn, loss, params, opt_state, train, train_eval, test_eval, epochs=3001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35401204",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3815f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Run multiple colobars while varying batch and initial params\n",
    "# Implement paper to reduce dimension while preserving dot product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98540e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/jovyan/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33f9a1818f2443facf5dc6d1dccf40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /home/jovyan/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Initialize deep cnn\n",
    "train, train_eval, test_eval = get_mnist_data(1000)\n",
    "batch = next(train)\n",
    "cnn, loss = network_and_loss(deepest_cnn)\n",
    "params = cnn.init(jax.random.PRNGKey(2), next(train))\n",
    "\n",
    "# out of memory error, two many network parameters to compute 1000 pointwise gradients at once\n",
    "# pointwise_gradients = ptwise_grads(loss)(params, batch)\n",
    "# gradient_features = ravel_pytree(pointwise_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bbc9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Couple methods for going about this:\n",
    "    # for each point, compute pointwise gradient then reduce dimension\n",
    "    # Compute pointwise gradients in minibatches and reduce dimension\n",
    "    \n",
    "\n",
    "def Achlio_matrix(large_dim, small_dim, prng_key):\n",
    "    print(large_dim)\n",
    "    mat =  random.choice(prng_key, np.array([-1, 0, 1]), \n",
    "                         shape=(large_dim,), p=np.array([1./6., 2./3., 1./6.]), replace=True)\n",
    "    return jnp.sqrt(3)*mat\n",
    "    \n",
    "\n",
    "def features_for_point(loss):\n",
    "    \n",
    "\n",
    "    def helper(batch, params):\n",
    "        point = {}\n",
    "        point['image'] = jnp.expand_dims(batch['image'], axis=0)\n",
    "        point['label'] = jnp.expand_dims(batch['label'], axis=0)\n",
    "        gradient = jax.grad(loss)(params, point)\n",
    "        leaves, _ = jax.tree_flatten(gradient)\n",
    "        features = jnp.concatenate([jnp.reshape(elt, -1) for elt in leaves], axis=0)\n",
    "        return features\n",
    "    return helper\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ea836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def one_feature(key, old_features):\n",
    "    vec = jnp.ravel(Achlio_matrix(old_features.shape[0],1, key))\n",
    "    return jnp.dot(vec, old_features)\n",
    "\n",
    "def all_features(loss, params):\n",
    "\n",
    "    def helper(keys, single_point):\n",
    "        old_features = features_for_point(loss)(single_point, params)\n",
    "        return jnp.array([one_feature(keys[i], old_features) for i in range(1000)])\n",
    "    return helper\n",
    "\n",
    "def new_all_features(loss, params):\n",
    "    @jax.jit\n",
    "    def helper(keys, single_point):\n",
    "        old_features = features_for_point(loss)(single_point, params)\n",
    "        @jax.jit\n",
    "        def f(carry, key):\n",
    "            return carry, one_feature(key, old_features)\n",
    "        _, res = jax.lax.scan(f, None, keys)\n",
    "        return res\n",
    "    return helper\n",
    "\n",
    "def all_points_in_batch(loss, params):\n",
    "    @jax.jit\n",
    "    def helper(keys, batch):\n",
    "        compute_one_features = new_all_features(loss, params)\n",
    "        @jax.jit\n",
    "        def f(carry, point):\n",
    "            return carry, compute_one_features(keys, point)\n",
    "        _, res = jax.lax.scan(f, None, batch)\n",
    "        return res\n",
    "    return helper\n",
    "\n",
    "def get_keys(seq, num_keys):\n",
    "    return jnp.array([next(seq) for i in range(num_keys)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e704e6",
   "metadata": {},
   "source": [
    "## Try with different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d81e8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jit\n",
    "func = all_points_in_batch(loss, params)\n",
    "seq = hk.PRNGSequence(42)\n",
    "def get_keys(seq, num_keys):\n",
    "    return jnp.array([next(seq) for i in range(num_keys)])\n",
    "keys = get_keys(seq, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e28d2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758554\n"
     ]
    }
   ],
   "source": [
    "compute_final_features = all_points_in_batch(loss, params)\n",
    "final_features = compute_final_features(keys, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c545c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_features*jnp.sqrt(1./200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cf4e2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  12.  13.  10.5 12.   4.5 10.5  9.  11.  10.5]\n",
      " [12.  12.   9.5 14.  12.   6.   9.  11.5 16.5 12.5]\n",
      " [13.   9.5  6.   8.5 11.5 11.   6.5 12.  13.5 12.5]\n",
      " [10.5 14.   8.5 16.   7.   8.   9.5 13.   7.  12.5]\n",
      " [12.  12.  11.5  7.   9.   9.   5.  13.  11.5  9.5]\n",
      " [ 4.5  6.  11.   8.   9.   4.   6.   5.5  7.5  8.5]\n",
      " [10.5  9.   6.5  9.5  5.   6.   6.  11.   9.5 10. ]\n",
      " [ 9.  11.5 12.  13.  13.   5.5 11.  14.  10.  13. ]\n",
      " [11.  16.5 13.5  7.  11.5  7.5  9.5 10.   7.   8. ]\n",
      " [10.5 12.5 12.5 12.5  9.5  8.5 10.  13.   8.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "distances = avg_sim(final_features, batch['label'], list(range(10)), hk.PRNGSequence(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a53053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f81c0109af0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "452709c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_params, _ = jax.tree_flatten(jax.grad(loss)(params, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f55efa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758554,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.concatenate([jnp.reshape(elt, -1) for elt in flattened_params], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c32846",
   "metadata": {},
   "source": [
    "## Old, small network to compare the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b14b862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize deep cnn\n",
    "train, train_eval, test_eval = get_mnist_data(1000)\n",
    "batch = next(train)\n",
    "cnn, loss = network_and_loss(net_fn_cnn)\n",
    "params = cnn.init(jax.random.PRNGKey(2), next(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5438374",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_features = ptwise_grads(loss)(params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a039cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = ravel_pytree(og_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16bd1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 53002)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a07d9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  12.  13.  10.5 12.   4.5 10.5  9.  11.  10.5]\n",
      " [12.  12.   9.5 14.  12.   6.   9.  11.5 16.5 12.5]\n",
      " [13.   9.5  6.   8.5 11.5 11.   6.5 12.  13.5 12.5]\n",
      " [10.5 14.   8.5 16.   7.   8.   9.5 13.   7.  12.5]\n",
      " [12.  12.  11.5  7.   9.   9.   5.  13.  11.5  9.5]\n",
      " [ 4.5  6.  11.   8.   9.   4.   6.   5.5  7.5  8.5]\n",
      " [10.5  9.   6.5  9.5  5.   6.   6.  11.   9.5 10. ]\n",
      " [ 9.  11.5 12.  13.  13.   5.5 11.  14.  10.  13. ]\n",
      " [11.  16.5 13.5  7.  11.5  7.5  9.5 10.   7.   8. ]\n",
      " [10.5 12.5 12.5 12.5  9.5  8.5 10.  13.   8.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "distances = avg_sim(flattened, batch['label'], list(range(10)), hk.PRNGSequence(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "898aae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f815420a0a0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "405e2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = all_points_in_batch(loss, params)\n",
    "seq = hk.PRNGSequence(42)\n",
    "keys = get_keys(seq, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22f1e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53002\n"
     ]
    }
   ],
   "source": [
    "compute_final_features = all_points_in_batch(loss, params)\n",
    "final_features = compute_final_features(keys, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfed2892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  12.  13.  10.5 12.   4.5 10.5  9.  11.  10.5]\n",
      " [12.  12.   9.5 14.  12.   6.   9.  11.5 16.5 12.5]\n",
      " [13.   9.5  6.   8.5 11.5 11.   6.5 12.  13.5 12.5]\n",
      " [10.5 14.   8.5 16.   7.   8.   9.5 13.   7.  12.5]\n",
      " [12.  12.  11.5  7.   9.   9.   5.  13.  11.5  9.5]\n",
      " [ 4.5  6.  11.   8.   9.   4.   6.   5.5  7.5  8.5]\n",
      " [10.5  9.   6.5  9.5  5.   6.   6.  11.   9.5 10. ]\n",
      " [ 9.  11.5 12.  13.  13.   5.5 11.  14.  10.  13. ]\n",
      " [11.  16.5 13.5  7.  11.5  7.5  9.5 10.   7.   8. ]\n",
      " [10.5 12.5 12.5 12.5  9.5  8.5 10.  13.   8.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "distances = avg_sim(jnp.sqrt(1./200)*final_features, batch['label'], list(range(10)), hk.PRNGSequence(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd358dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f813c78c8e0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(distances)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ddfb5",
   "metadata": {},
   "source": [
    "What's good about the above is that the magnitudes of the \"reduced\" inner products match the magnitudes of the \"true\" ones. Next, we follow Robert's suggestion and compute the variance between the inner products.\n",
    "\n",
    "To compute the variance, we will do the following:\n",
    "- compute the gradient features (batch_size x num_params)\n",
    "- compute the reduced dimension features (bath_size x dim)\n",
    "- compute pairwise inner products for both (batch_size x batch_size)\n",
    "- take the difference between these two matrices and calculate mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e558c58",
   "metadata": {},
   "source": [
    "### Compute true gradient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a82473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_eval, test_eval = get_mnist_data(1000)\n",
    "batch = next(train)\n",
    "cnn, loss = network_and_loss(net_fn_cnn)\n",
    "params = cnn.init(jax.random.PRNGKey(2), next(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841fdea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 53002)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_features = ptwise_grads(loss)(params, batch)\n",
    "flattened = ravel_pytree(og_features)\n",
    "flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798cc1f",
   "metadata": {},
   "source": [
    "### Compute reduced dimension features (200, 500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adf38091",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_final_features = all_points_in_batch(loss, params)\n",
    "\n",
    "\n",
    "seq = hk.PRNGSequence(24)\n",
    "small_keys = get_keys(seq, 200)\n",
    "med_keys = get_keys(seq, 500)\n",
    "large_keys = get_keys(seq, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "041af219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53002\n",
      "53002\n",
      "53002\n"
     ]
    }
   ],
   "source": [
    "small_final_features = jnp.sqrt(1./200)*compute_final_features(small_keys, batch)\n",
    "med_final_features = jnp.sqrt(1./500)*compute_final_features(med_keys, batch)\n",
    "large_final_features = jnp.sqrt(1./1000)*compute_final_features(large_keys, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986db8d",
   "metadata": {},
   "source": [
    "### Compute pairwise inner products for both sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9a598d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return jnp.dot(x,y)\n",
    "\n",
    "temp = jax.vmap(inner, in_axes=(0, None))\n",
    "pairwise_products = jax.vmap(test, in_axes=(None, 0), out_axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f48961d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_pairwise = pairwise_products(flattened, flattened)\n",
    "small_pairwise = pairwise_products(small_final_features, small_final_features)\n",
    "med_pairwise = pairwise_products(med_final_features, med_final_features)\n",
    "large_pairwise = pairwise_products(large_final_features, large_final_features)\n",
    "\n",
    "small_diffs = small_pairwise - og_pairwise\n",
    "med_diffs = med_pairwise - og_pairwise\n",
    "large_diffs = large_pairwise - og_pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968c9ca",
   "metadata": {},
   "source": [
    "### Compute mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12b908bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 496.9286193847656, Min: -91.12599182128906\n",
      "Median: -12.06199836730957\n",
      "Mean: 28.586336135864258\n"
     ]
    }
   ],
   "source": [
    "# for reference: the \"true\" pairwise products are stored in \"og_pairwise\"\n",
    "print(\"Max: {}, Min: {}\".format(jnp.max(og_pairwise), jnp.min(og_pairwise)))\n",
    "print(\"Median: {}\".format(jnp.median(og_pairwise)))\n",
    "print(\"Mean: {}\".format(jnp.mean(jnp.abs(og_pairwise))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a652c102",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 2 7 6 1 1 3 3 3 2 7 3 2 1 7 3 3 5 6 9 1 3 4 9 5 5 2 7 3 6 7 4 7 8 0 3\n",
      " 1 4 8 9 5 4 2 1 4 3 6 2 8 4 1 4 8 8 2 0 7 3 0 6 4 8 1 3 3 5 1 6 9 5 0 2 0\n",
      " 2 8 5 2 8 3 5 1 7 9 3 1 7 6 0 9 8 7 2 7 7 2 1 7 0 6 0 1 6 1 2 8 0 8 5 6 0\n",
      " 4 9 6 3 3 6 4 3 9 9 9 1 2 3 4 9 1 9 0 2 6 4 4 0 8 8 1 3 4 6 0 7 9 3 9 2 4\n",
      " 7 5 9 1 8 4 4 3 3 7 2 0 0 6 3 9 6 7 6 1 8 1 6 6 2 1 7 1 0 7 2 4 4 8 5 3 9\n",
      " 3 1 9 6 8 5 7 4 5 2 8 1 3 0 2 7 1 4 7 2 7 4 2 4 7 0 0 4 7 6 1 3 2 1 6 6 1\n",
      " 9 6 0 7 1 5 3 1 2 1 8 2 8 2 0 3 5 5 7 2 9 6 6 8 7 6 3 5 3 5 4 0 2 8 0 8 9\n",
      " 0 7 6 0 4 2 6 4 7 0 3 1 7 7 0 2 7 2 0 3 0 0 5 4 3 0 0 3 3 1 3 0 0 3 3 9 9\n",
      " 8 9 5 0 5 6 2 1 4 1 4 7 6 3 2 1 2 0 2 6 5 2 4 8 8 4 9 3 1 7 6 9 0 6 9 7 5\n",
      " 0 5 7 5 2 2 5 5 9 1 9 9 6 7 9 3 7 0 9 9 5 9 0 4 8 0 2 4 7 7 9 6 0 7 3 8 3\n",
      " 4 4 7 8 7 3 4 3 1 8 9 8 9 0 1 4 8 0 8 8 9 8 1 6 6 2 0 9 4 0 5 3 8 6 8 9 8\n",
      " 5 3 6 3 0 3 6 3 9 3 6 2 6 1 3 6 6 2 3 1 0 6 5 6 7 7 9 2 7 9 4 4 0 4 8 7 2\n",
      " 4 6 8 2 1 5 8 2 5 3 2 8 4 3 2 6 8 9 2 8 3 8 2 5 0 4 6 4 1 0 6 1 9 1 8 8 2\n",
      " 5 3 4 1 1 3 1 7 6 0 5 2 4 6 9 3 4 8 9 1 5 8 7 3 2 4 4 6 1 3 1 5 1 7 6 7 6\n",
      " 9 7 0 5 3 4 3 6 9 9 1 2 6 7 7 7 4 7 7 8 8 2 4 2 3 2 2 2 0 1 1 4 8 4 9 6 6\n",
      " 2 8 2 9 5 0 9 5 8 2 7 5 1 5 9 8 7 1 1 9 7 4 2 3 8 1 7 2 2 2 9 1 7 7 7 1 9\n",
      " 7 2 1 9 0 4 8 9 0 9 1 7 1 2 8 8 5 7 3 5 7 9 5 8 7 8 8 9 8 5 9 7 5 1 8 1 1\n",
      " 3 6 6 1 0 4 4 1 1 7 5 2 7 4 1 3 6 8 4 7 0 1 1 7 4 1 6 3 3 0 1 0 6 1 2 5 9\n",
      " 6 8 0 5 7 1 0 3 9 5 8 0 9 9 1 8 1 3 8 4 5 7 9 6 7 5 0 4 8 0 1 0 1 8 9 9 0\n",
      " 3 8 8 6 1 5 9 8 0 7 3 4 3 4 5 6 9 6 9 0 9 0 1 1 9 9 3 0 5 4 9 3 1 0 1 7 8\n",
      " 5 3 1 3 6 0 6 7 7 8 6 2 3 4 4 8 9 2 7 5 7 9 5 6 9 1 2 5 8 3 8 2 9 1 4 2 9\n",
      " 7 9 8 9 7 3 0 7 9 1 1 3 4 9 9 8 9 5 5 0 3 5 1 6 4 2 9 8 4 2 0 2 7 7 2 1 1\n",
      " 4 4 1 8 4 1 6 7 9 0 6 2 4 6 7 3 3 7 0 8 9 2 4 5 3 3 4 4 7 6 9 8 5 5 7 7 7\n",
      " 0 7 7 2 6 0 2 1 7 1 1 8 2 3 1 0 5 3 5 5 2 5 1 8 5 2 2 7 0 3 3 0 8 5 5 7 4\n",
      " 3 8 1 2 1 9 2 1 5 4 8 8 3 0 0 4 3 7 0 3 1 7 9 8 6 0 5 3 7 7 4 8 3 1 9 0 4\n",
      " 3 7 2 7 5 0 4 3 7 6 2 0 8 0 7 0 8 7 1 0 4 8 4 2 0 7 6 2 0 9 0 4 1 7 6 6 3\n",
      " 1 0 3 4 4 2 6 7 1 9 2 4 5 9 3 8 8 7 1 6 8 1 4 7 8 9 8 9 4 8 6 3 4 6 7 0 6\n",
      " 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(168.765, dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch['label'])\n",
    "og_pairwise[34][39]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431ad83",
   "metadata": {},
   "source": [
    "200 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26f9bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.18189573287963867\n",
      "Variance: 246.5001983642578\n",
      "Std dev: 15.700325012207031\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: {}\".format(jnp.mean(small_diffs)))\n",
    "print(\"Variance: {}\".format(jnp.var(small_diffs)))\n",
    "print(\"Std dev: {}\".format(jnp.std(small_diffs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7537df",
   "metadata": {},
   "source": [
    "500 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34f0b2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0737052783370018\n",
      "Variance: 112.04792022705078\n",
      "Std dev: 10.585269927978516\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: {}\".format(jnp.mean(med_diffs)))\n",
    "print(\"Variance: {}\".format(jnp.var(med_diffs)))\n",
    "print(\"Std dev: {}\".format(jnp.std(med_diffs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613aed4",
   "metadata": {},
   "source": [
    "1000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8ed944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.02094210684299469\n",
      "Variance: 48.74789810180664\n",
      "Std dev: 6.981969356536865\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: {}\".format(jnp.mean(large_diffs)))\n",
    "print(\"Variance: {}\".format(jnp.var(large_diffs)))\n",
    "print(\"Std dev: {}\".format(jnp.std(large_diffs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76b9ce",
   "metadata": {},
   "source": [
    "# NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a184c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def one_feature(key, old_features):\n",
    "    vec = jnp.ravel(Achlio_matrix(old_features.shape[0],1, key))\n",
    "    return jnp.dot(vec, old_features)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def new_features(keys, old_features):\n",
    "    @jax.jit\n",
    "    def f(carry, key):\n",
    "        return carry, one_feature(key, old_features)\n",
    "    _, res = jax.lax.scan(f, None, keys)\n",
    "    return res\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def all_new_features(keys, batch):\n",
    "    @jax.jit\n",
    "    def f(carry, point):\n",
    "        return carry, new_features(keys, point)\n",
    "    _, res = jax.lax.scan(f, None, batch)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_keys(seq, num_keys):\n",
    "    return jnp.array([next(seq) for i in range(num_keys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcaea3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a94afb0b8434fff876d75e58498b511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.3 s  2.46 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from jax import jacrev\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_points = 10000\n",
    "num_features = 10000\n",
    "batch_size = 10\n",
    "train = load_dataset('mnist', \"train[0:{}]\".format(num_points), is_training=True, batch_size=batch_size)\n",
    "net, loss = network_and_loss(net_fn_cnn)\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "\n",
    "all_reduced_features = np.zeros((num_points, num_features))\n",
    "\n",
    "for idx, batch in tqdm(enumerate(train), total=num_points/batch_size, desc=\"Progress\"):\n",
    "\n",
    "    \n",
    "    \n",
    "    f = lambda params: net.apply(params,batch)\n",
    "    J = jacrev(f)(params)\n",
    "    features = ravel_pytree(J)\n",
    "    keys = get_keys(hk.PRNGSequence(42), num_features)\n",
    "    \n",
    "    # dimension reduce\n",
    "    %timeit new_features = all_new_features(keys, features)\n",
    "\n",
    "    # move to cpu\n",
    "    all_reduced_features[idx*batch_size:(idx+1)*batch_size] = new_features\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d27fb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe75b053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_dataset('mnist', \"train[0:{}]\".format(num_points), is_training=True, batch_size=batch_size)\n",
    "params = net.init(jax.random.PRNGKey(42), next(train))\n",
    "batch = next(train)\n",
    "f = lambda params: net.apply(params,batch)\n",
    "J = jacrev(f)(params)\n",
    "keys = get_keys(hk.PRNGSequence(42), num_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
